{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae7f5938",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "### Definition\n",
    "-> Regression is a **supervised learning** technique used to predict a **continuous target variable**.\n",
    "\n",
    "### Key Points\n",
    "- Input (X) → Continuous/Discrete\n",
    "- Output (y) → Continuous\n",
    "- Examples: House price prediction, stock price forecasting, salary estimation\n",
    "\n",
    "### Types of Regression\n",
    "- Linear Regression\n",
    "- Polynomial Regression\n",
    "- Ridge & Lasso Regression\n",
    "- Logistic Regression (classification but derived from regression)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9ec7ec",
   "metadata": {},
   "source": [
    "### 1. Linear Regression\n",
    "\n",
    "- Relationship between X and y is **linear**.\n",
    "- Equation:  \n",
    "  $$\n",
    "  y = β_0 + β_1x_1 + β_2x_2 + ... + β_nx_n + ε\n",
    "  $$\n",
    "  where:\n",
    "  - \\( β_0 \\) → intercept  \n",
    "  - \\( β_i \\) → coefficients  \n",
    "  - \\( ε \\) → error term  \n",
    "\n",
    "- Example: Predicting house prices based on size.\n",
    "- Example: Predicting salary using experience, age, and education.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ce8737",
   "metadata": {},
   "source": [
    "### 2. Polynomial Regression\n",
    "\n",
    "- Fits a **curved relationship** between X and y.\n",
    "- Equation:\n",
    "\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1x + \\beta_2x^2 + \\beta_3x^3 + \\dots + \\beta_nx^n\n",
    "$$\n",
    "\n",
    "- Example: Growth trends like population or sales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be42cc3",
   "metadata": {},
   "source": [
    "### 3. Ridge Regression (L2 Regularization)\n",
    "\n",
    "- Adds **penalty on squared magnitude of coefficients**.  \n",
    "- Helps reduce **overfitting**.\n",
    "- Cost Function:\n",
    "\n",
    "$$\n",
    "J = MSE + \\lambda \\sum_{i=1}^n \\beta_i^2\n",
    "$$\n",
    "- where:  \n",
    "    - $ J $ → cost function  \n",
    "    - $ MSE $ → mean squared error  \n",
    "    - $ \\lambda $ → regularization parameter (controls penalty strength)  \n",
    "    - $ \\beta_i $ → coefficients \n",
    "- Useful when predictors are highly correlated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f440bd08",
   "metadata": {},
   "source": [
    "### 4. Lasso Regression (L1 Regularization)\n",
    "\n",
    "- Adds **penalty on absolute value** of coefficients.  \n",
    "- Shrinks some coefficients to **zero → feature selection**.  \n",
    "- Cost Function:\n",
    "\n",
    "$$\n",
    "J = MSE + \\lambda \\sum_{i=1}^n |\\beta_i|\n",
    "$$\n",
    "\n",
    "where:  \n",
    "- $ J $ → cost function  \n",
    "- $ MSE $ → mean squared error  \n",
    "- $ \\lambda $ → regularization parameter  \n",
    "- $ \\beta_i $ → coefficients  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5c311d",
   "metadata": {},
   "source": [
    "### 5. Elastic Net Regression\n",
    "\n",
    "- Combination of **Ridge (L2)** and **Lasso (L1)**.  \n",
    "- Cost Function:\n",
    "\n",
    "$$\n",
    "J = MSE + \\lambda_1 \\sum_{i=1}^n |\\beta_i| + \\lambda_2 \\sum_{i=1}^n \\beta_i^2\n",
    "$$\n",
    "\n",
    "where:  \n",
    "- $ J $ → cost function  \n",
    "- $ MSE $ → mean squared error  \n",
    "- $ \\lambda_1 $ → L1 penalty factor  \n",
    "- $ \\lambda_2 $ → L2 penalty factor  \n",
    "- $ \\beta_i $ → coefficients  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133077d6",
   "metadata": {},
   "source": [
    "### 7. Logistic Regression (for Classification)\n",
    "\n",
    "- Despite the name, used for **classification**.  \n",
    "- Uses **sigmoid function** to map predictions between 0 and 1.  \n",
    "- Equation:\n",
    "\n",
    "$$\n",
    "P(y=1|X) = \\frac{1}{1+e^{-(\\beta_0 + \\beta_1x)}}\n",
    "$$\n",
    "\n",
    "where:  \n",
    "- $ P(y=1|X) $ → probability that class = 1  \n",
    "- $ e $ → exponential function  \n",
    "- $ \\beta_0 $ → intercept  \n",
    "- $ \\beta_1 $ → coefficient of feature $x$  \n",
    "- $ x $ → independent variable  \n",
    "\n",
    "\n",
    "### 8. Support Vector Regression (SVR)\n",
    "\n",
    "- Based on **Support Vector Machines (SVM)**.  \n",
    "- Fits data within a **margin of tolerance (ε)**.  \n",
    "- Objective: minimize errors outside $ \\epsilon $.\n",
    "\n",
    "Equation (loss intuition):\n",
    "\n",
    "$$\n",
    "L = \\max(0, |y - f(x)| - \\epsilon)\n",
    "$$\n",
    "\n",
    "where:  \n",
    "- $ L $ → loss function  \n",
    "- $ y $ → true value  \n",
    "- $ f(x) $ → predicted value  \n",
    "- $ \\epsilon $ → margin of tolerance  \n",
    "\n",
    "\n",
    "### 9. Quantile Regression\n",
    "\n",
    "- Predicts **quantiles (median, percentiles)** instead of mean.  \n",
    "- More robust to outliers.  \n",
    "- Equation:\n",
    "\n",
    "$$\n",
    "Q_y(\\tau | X) = X\\beta\n",
    "$$\n",
    "\n",
    "where:  \n",
    "- $ Q_y(\\tau|X) $ → conditional quantile of y given X  \n",
    "- $ \\tau $ → quantile level (0.5 for median, 0.25 for 25th percentile, etc.)  \n",
    "- $ \\beta $ → coefficients  \n",
    "\n",
    "\n",
    "### 10. Bayesian Regression\n",
    "\n",
    "- Uses **Bayes’ Theorem** to estimate regression coefficients.  \n",
    "- Produces a **distribution** for coefficients instead of fixed values.  \n",
    "- Formula (posterior):\n",
    "\n",
    "$$\n",
    "P(\\beta | X, y) = \\frac{P(y|X, \\beta) \\cdot P(\\beta)}{P(y|X)}\n",
    "$$\n",
    "\n",
    "where:  \n",
    "- $ P(\\beta | X, y) $ → posterior probability of coefficients  \n",
    "- $ P(y|X, \\beta) $ → likelihood of data  \n",
    "- $ P(\\beta) $ → prior belief of coefficients  \n",
    "- $ P(y|X) $ → evidence  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dee292",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "- **Linear & Multiple Linear Regression** → Simple relationships  \n",
    "- **Polynomial Regression** → Non-linear trends  \n",
    "- **Ridge, Lasso, Elastic Net** → Regularization techniques  \n",
    "- **Logistic Regression** → Classification  \n",
    "- **SVR, Quantile, Bayesian** → Advanced regression methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f02c34",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
