{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cf69889",
   "metadata": {},
   "source": [
    "# Validation Set & Cross-Validation\n",
    "\n",
    "---\n",
    "\n",
    "## Validation Set\n",
    "Besides splitting into **train** and **test**, we can further split data into:\n",
    "\n",
    "- **Training Set** → used to fit the model  \n",
    "- **Validation Set** → used for tuning hyperparameters & model selection  \n",
    "- **Testing Set** → used only for final evaluation  \n",
    "\n",
    "This helps in preventing **data leakage** and ensures fair evaluation.\n",
    "\n",
    "---\n",
    "\n",
    "## Example Split (80/20 rule)\n",
    "- 60% Training  \n",
    "- 20% Validation  \n",
    "- 20% Testing  \n",
    "\n",
    "---\n",
    "\n",
    "## Limitation of Train / Validation / Test\n",
    "- Sometimes dataset is small → splitting into 3 parts reduces training data.\n",
    "- Performance may vary depending on how data is split.\n",
    "\n",
    "---\n",
    "\n",
    "# Cross-Validation (CV)\n",
    "\n",
    "To overcome small dataset issues, we use **Cross-Validation**.\n",
    "\n",
    "---\n",
    "\n",
    "## k-Fold Cross-Validation\n",
    "1. Split the dataset into **k equal folds**.  \n",
    "2. Train on **k-1 folds** and test on the **remaining fold**.  \n",
    "3. Repeat the process **k times**, each time changing the test fold.  \n",
    "4. Average the results to get the final performance.\n",
    "\n",
    "---\n",
    "\n",
    "## Formula\n",
    "\n",
    "If dataset = $D$ and folds = $k$:\n",
    "\n",
    "$$\n",
    "Accuracy = \\frac{1}{k} \\sum_{i=1}^{k} Accuracy_i\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $Accuracy_i$ → accuracy on $i^{th}$ fold  \n",
    "- $k$ → number of folds (commonly 5 or 10)\n",
    "\n",
    "---\n",
    "\n",
    "## Advantages of k-Fold CV\n",
    "- Uses the **entire dataset** for both training & testing.  \n",
    "- Reduces variance due to a single split.  \n",
    "- Works well with small datasets.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "078ee619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.99445983 0.99836735 0.96051054 0.99506043]\n",
      "Average R²: 0.9870995380002167\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "X = np.array([[1], [2], [3], [4], [5], [6], [7], [8]])\n",
    "y = np.array([1.2, 2.3, 2.9, 4.2, 5.1, 6.1, 7.0, 8.2])\n",
    "\n",
    "# Model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Define 4-Fold CV\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate using cross-validation\n",
    "scores = cross_val_score(model, X, y, cv=kf, scoring=\"r2\")\n",
    "\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Average R²:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0de956a",
   "metadata": {},
   "source": [
    "# Stratified k-Fold Cross-Validation\n",
    "\n",
    "---\n",
    "\n",
    "## What is it?\n",
    "- A special version of **k-Fold CV**.  \n",
    "- Ensures each fold has the **same class proportion** as the original dataset.  \n",
    "- Useful when data is **imbalanced** (e.g., 90% class A, 10% class B).  \n",
    "\n",
    "---\n",
    "\n",
    "## Why Stratification?\n",
    "- Normal k-Fold may create folds with uneven class distributions.  \n",
    "- Stratification prevents bias → each fold represents the population properly.  \n",
    "\n",
    "---\n",
    "\n",
    "## Advantages\n",
    "- Works better for classification problems with **imbalanced data**.  \n",
    "- Reduces risk of misleading accuracy.  \n",
    "\n",
    "---\n",
    "\n",
    "## Example\n",
    "Suppose dataset has 100 samples:\n",
    "- 80 are Class 0  \n",
    "- 20 are Class 1  \n",
    "\n",
    "With **5-Fold Stratified CV**:  \n",
    "- Each fold will contain ~16 Class 0 and ~4 Class 1 → balanced evaluation.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "633d81a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified CV scores: [1.   1.   0.75 1.   1.  ]\n",
      "Average Accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "# Sample dataset (features + binary labels)\n",
    "X = np.array([[i] for i in range(1, 21)])\n",
    "y = np.array([0]*15 + [1]*5)  # Imbalanced dataset\n",
    "\n",
    "# Model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Define Stratified 5-Fold CV\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate using cross-validation\n",
    "scores = cross_val_score(model, X, y, cv=skf, scoring=\"accuracy\")\n",
    "\n",
    "print(\"Stratified CV scores:\", scores)\n",
    "print(\"Average Accuracy:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cb58e9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
