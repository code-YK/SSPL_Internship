{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68a71d74",
   "metadata": {},
   "source": [
    "# Bootstrapping in Machine Learning and Statistics\n",
    "\n",
    "This notebook covers Bootstrapping from scratch to end-to-end:\n",
    "- Introduction\n",
    "- Core Concepts\n",
    "- The Algorithm\n",
    "- Mathematical Background\n",
    "- Why Bootstrapping Works\n",
    "- Example Intuition\n",
    "- Implementation in Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15e5324",
   "metadata": {},
   "source": [
    "## 1. What is Bootstrapping?\n",
    "\n",
    "Bootstrapping is a **statistical resampling technique** that involves:\n",
    "- Sampling **with replacement** from a dataset.\n",
    "- Creating many \"bootstrap samples\".\n",
    "- Estimating statistics (mean, variance, confidence intervals) by repeating the process.\n",
    "\n",
    "The idea is to approximate the **sampling distribution** of a statistic when the true population distribution is unknown.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872d6582",
   "metadata": {},
   "source": [
    "## 2. Core Concepts\n",
    "\n",
    "- **Population**: The entire set of data (unknown in practice).\n",
    "- **Sample**: A subset of the population (what we actually observe).\n",
    "- **Bootstrap Sample**: A new dataset created by sampling **with replacement** from the original sample.\n",
    "- **Bootstrap Replicates**: The statistics computed from bootstrap samples (e.g., mean, median).\n",
    "- **Bootstrap Distribution**: The distribution of these replicates, which approximates the true sampling distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fab3da6",
   "metadata": {},
   "source": [
    "## 3. The Bootstrapping Algorithm (Step by Step)\n",
    "\n",
    "Given dataset $D = \\{x_1, x_2, \\dots, x_N\\}$:\n",
    "\n",
    "1. Draw a bootstrap sample $D^*$ of size $N$ by sampling **with replacement** from $D$.\n",
    "2. Compute the statistic of interest $\\theta^*$ (mean, variance, regression coefficient, etc.) on $D^*$.\n",
    "3. Repeat steps 1â€“2 $B$ times (e.g., 1000 times) to obtain $\\{\\theta_1^*, \\theta_2^*, \\dots, \\theta_B^*\\}$.\n",
    "4. Use this distribution of $\\theta^*$ values to estimate:\n",
    "   - Bias\n",
    "   - Variance\n",
    "   - Standard error\n",
    "   - Confidence intervals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560bf4ca",
   "metadata": {},
   "source": [
    "## 4. Mathematical Background\n",
    "\n",
    "- Suppose the true statistic of interest is $\\theta$.\n",
    "- The bootstrap approximates the sampling distribution of $\\theta$ using the empirical distribution of the observed data.\n",
    "- If $F$ is the true distribution and $\\hat{F}$ is the empirical distribution, then the bootstrap approximates:\n",
    "\n",
    "$$\n",
    "P^*(\\theta) \\approx P(\\theta)\n",
    "$$\n",
    "\n",
    "- Confidence Interval (Percentile Method):\n",
    "\n",
    "$$\n",
    "\\text{CI}_{95\\%} = [\\theta^*_{2.5\\%}, \\; \\theta^*_{97.5\\%}]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a92b71a",
   "metadata": {},
   "source": [
    "## 5. Why Bootstrapping Works\n",
    "\n",
    "- Traditional statistics assume large samples or known distributions (e.g., normality).\n",
    "- In reality, data may be small or non-normal.\n",
    "- Bootstrapping works because it relies on **resampling the observed data** to mimic repeated sampling from the population.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774d12b0",
   "metadata": {},
   "source": [
    "## 6. Intuition Example\n",
    "\n",
    "Imagine we have only 10 test scores from students.  \n",
    "We want to estimate the average score and its confidence interval.  \n",
    "\n",
    "- With bootstrapping, we repeatedly resample (with replacement) 10 scores at a time.\n",
    "- Each resample gives us a slightly different mean.\n",
    "- After 1000 resamples, we get a distribution of means.\n",
    "- From this distribution, we can compute the mean, variance, and confidence intervals of the true population mean.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368a6826",
   "metadata": {},
   "source": [
    "## 7. Applications in Machine Learning\n",
    "\n",
    "- Estimating confidence intervals of model parameters.\n",
    "- Feature importance estimation (Random Forests use bootstrapping internally).\n",
    "- Out-of-bag error estimation in Bagging.\n",
    "- Model validation when data is limited.\n",
    "- Robust error estimation without strong assumptions about data distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae3464a",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "- Bootstrapping is a powerful, non-parametric resampling method.\n",
    "- It helps estimate statistics, variance, and confidence intervals without strict assumptions.\n",
    "- It is the foundation of Bagging and Random Forests.\n",
    "- Works especially well for small datasets and complex statistics where traditional formulas are not available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b675147",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
